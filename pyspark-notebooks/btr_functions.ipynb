{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "#MLlib\n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_train_info(model):\n",
    "    print(\"Model:\")\n",
    "    print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "    print(\"Intercept: %s\" % str(model.intercept))\n",
    "    print(\"  \")\n",
    "    print(\"Model info\")\n",
    "    trainingSummary = model.summary\n",
    "    print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "    print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "    print(\"MAE: %f\" % trainingSummary.meanAbsoluteError)\n",
    "    print(\"r2: %f\" % trainingSummary.r2)\n",
    "\n",
    "def print_eval_info(model_eval):\n",
    "    print(\"Eval info:\")\n",
    "    print(\"RMSE: %f\" % model_eval.rootMeanSquaredError)\n",
    "    print(\"MAE: %f\" % model_eval.meanAbsoluteError)\n",
    "    print(\"r2: %f\" % model_eval.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(sqlContext, filepath = \"data/curitiba/prediction_data.csv\"):\n",
    "    df = sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(filepath)\n",
    "\n",
    "    df = df.withColumn('date_timestamp', df['date'].cast('Integer'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_pre_proc(df, string_columns = [\"route\", \"week_day\", \"difference_previous_schedule\", \"difference_next_schedule\"],\n",
    "                 features = [\"route_index\", \"date_timestamp\", \"week_day_index\", \"group_15_minutes\", \"difference_next_schedule_index\", \"difference_previous_schedule_index\"]):\n",
    "    indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in string_columns]\n",
    "    pipeline = Pipeline(stages=indexers)\n",
    "    df_r = pipeline.fit(df).transform(df)\n",
    "    \n",
    "    assembler = VectorAssembler(\n",
    "    inputCols=features,\n",
    "    outputCol='features')\n",
    "\n",
    "    assembled_df = assembler.transform(df_r)\n",
    "    \n",
    "    return assembled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_duration_model(training_df):\n",
    "    duration_lr = LinearRegression(maxIter=10, regParam=0.01, elasticNetParam=1.0).setLabelCol(\"duration\").setFeaturesCol(\"features\")\n",
    "\n",
    "    duration_lr_model = duration_lr.fit(training_df)\n",
    "    \n",
    "    return duration_lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_crowdedness_model(training_df):\n",
    "    crowdedness_lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=1).setLabelCol(\"totalpassengers\").setFeaturesCol(\"features\")\n",
    "\n",
    "    crowdedness_lr_model = crowdedness_lr.fit(training_df)\n",
    "    \n",
    "    return crowdedness_lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, test):\n",
    "    evaluated_data = model.evaluate(test)\n",
    "    return evaluated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, filepath):\n",
    "    model.write().overwrite().save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model = LinearRegressionModel):\n",
    "    return model.load(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext('local[*]')\n",
    "sqlContext = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration model\n",
      "Model:\n",
      "Coefficients: [-0.0700377141175,3.00967333739e-07,-0.531780521136,-2.41339298608e-05,-0.000596150175885,-0.00053062218407]\n",
      "Intercept: -401.380429639\n",
      "  \n",
      "Model info\n",
      "numIterations: 11\n",
      "RMSE: 20.849891\n",
      "MAE: 13.726247\n",
      "r2: 0.054802\n",
      "Eval info:\n",
      "RMSE: 20.260875\n",
      "MAE: 13.681778\n",
      "r2: 0.053832\n",
      "\n",
      "Crowdedness model\n",
      "Model:\n",
      "Coefficients: [0.00915223769642,0.0,-1.58388101245,-0.000145362432559,4.31352067881e-06,0.000313375439569]\n",
      "Intercept: 21.1096148246\n",
      "  \n",
      "Model info\n",
      "numIterations: 11\n",
      "RMSE: 14.368144\n",
      "MAE: 9.658412\n",
      "r2: 0.093718\n",
      "Eval info:\n",
      "RMSE: 14.005498\n",
      "MAE: 9.558157\n",
      "r2: 0.095711\n"
     ]
    }
   ],
   "source": [
    "data = read_data(sqlContext)\n",
    "\n",
    "preproc_data = data_pre_proc(data)\n",
    "\n",
    "train, test = preproc_data.randomSplit([0.6, 0.4], seed=0)\n",
    "\n",
    "print \"Duration model\"\n",
    "duration_model = train_duration_model(train)\n",
    "print_train_info(duration_model)\n",
    "\n",
    "duration_model_eval = predict(duration_model, test)\n",
    "print_eval_info(duration_model_eval)\n",
    "loaded_model = load_model(\"data/models/duration_lasso_model\")\n",
    "print \"\"\n",
    "\n",
    "print \"Crowdedness model\"\n",
    "crowdedness_model = train_crowdedness_model(train)\n",
    "print_train_info(crowdedness_model)\n",
    "\n",
    "crowdedness_model_eval = predict(crowdedness_model, test)\n",
    "print_eval_info(crowdedness_model_eval)\n",
    "loaded_model = load_model(\"data/models/crowdedness_lasso_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
